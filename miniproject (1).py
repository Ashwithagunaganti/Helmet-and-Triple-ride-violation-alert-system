# -*- coding: utf-8 -*-
"""miniproject

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MbriSEhnObFgwAO33gEp9es97ZVkYC6S
"""



!pip install opencv-python
import cv2
# load the cascade classifier for detecting faces and helmets
helmet_cascade = cv2.CascadeClassifier('/content/haarcascade_helmet (2).xml')
face_cascade = cv2.CascadeClassifier('/content/haarcascade_frontalface_default (1).xml')

# load the image
img = cv2.imread('/content/helmet.jpg')

# convert the image to grayscale
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

# detect faces in the image
faces = face_cascade.detectMultiScale(gray, 1.3, 5)

helmet_alert = True

for (x, y, w, h) in faces:
    # draw a rectangle around the face
    cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)

    # crop the face region
    face_roi = gray[y:y + h, x:x + w]

    # detect helmets in the face region
    helmets = helmet_cascade.detectMultiScale(face_roi, 1.3, 5)

    if len(helmets) == 0:
        # send alert message to wear a helmet
        helmet_alert = False
        break

if helmet_alert:

    print("good! you are wearing a helmet.")
else:
   !pip install twilio
from twilio.rest import Client

account_sid = 'AC5a45088aad593c466d5801730df2168c'
auth_token = 'd8a7694bf568a4eabfdae694cab858b6'
client = Client(account_sid, auth_token)

message = client.messages.create(
  from_='+13854817243',
  to='+9',
  body="please wear the helmet."
)

print(message.sid)


from google.colab.patches import cv2_imshow
cv2_imshow(img)

from google.colab.patches import cv2_imshow
import cv2

# load the image
image = cv2.imread('/content/tripleriding.jpeg')

# load pre-trained haar cascade classifier for pedestrian detection
classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_fullbody.xml')

# convert the image to grayscale
gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

# detect pedestrians in the image
pedestrians = classifier.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))

# count the number of pedestrians detected
num_pedestrians = len(pedestrians)

# display the image with pedestrian bounding boxes
for (x, y, w, h) in pedestrians:
    cv2.rectangle(image, (x, y), (x+w, y+h), (255, 0, 0), 2)

# send alert message based on the number of people on bike
if num_pedestrians >=3:
    print("Alert: Only two people are allowed on a bike!")
elif num_pedestrians >= 2:
    print("Good job! You are going with two persons on the bike.")
else:
  !pip install twilio
from twilio.rest import Client

account_sid = 'AC5a45088aad593c466d5801730df2168c'
auth_token = 'd8a7694bf568a4eabfdae694cab858b6'
client = Client(account_sid, auth_token)

message = client.messages.create(
  from_='+13854817243',
  to='+916',
  body="Alert: Only two people are allowed on a bike! have a safe ride." # Add the body parameter here
)

print(message.sid)

# display the image with pedestrian bounding boxes
cv2_imshow(image)
cv2.waitKey(0)
cv2.destroyAllWindows()



from google.colab.patches import cv2_imshow
import cv2

# load the image
image = cv2.imread('/content/tripleriding.jpeg')

# load pre-trained haar cascade classifier for pedestrian detection
classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_fullbody.xml')

# convert the image to grayscale
gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

# detect pedestrians in the image
pedestrians = classifier.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))

# count the number of pedestrians detected
num_pedestrians = len(pedestrians)

# display the image with pedestrian bounding boxes
for (x, y, w, h) in pedestrians:
    cv2.rectangle(image, (x, y), (x+w, y+h), (255, 0, 0), 2)
helmet_alert = True

for (x, y, w, h) in faces:
    # draw a rectangle around the face
    cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)

    # crop the face region
    face_roi = gray[y:y + h, x:x + w]


cv2.destroyAllWindows()



import cv2
from google.colab.patches import cv2_imshow

helmet_detector = cv2.CascadeClassifier('/content/haarcascade_helmet (2).xml')
person_detector = cv2.CascadeClassifier('/content/haarcascade_upperbody.xml')

image = cv2.imread('/content/tripleriding.jpeg')
gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

helmets = helmet_detector.detectMultiScale(gray_image, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))
persons = person_detector.detectMultiScale(gray_image, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))

for (x, y, w, h) in helmets:
    cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)

for (x, y, w, h) in persons:
    cv2.rectangle(image, (x, y), (x + w, y + h), (255, 0, 0), 2)

cv2_imshow(image)

if len(persons) >= 2:
    print("Only two people are allowed on the bike.")
    print("Only two people are allowed on the bike.")
else:
    print("Alert: Only two people are allowed on the bike.")

if len(helmets) > 0:
    print("Good to go! Helmets are being worn.")
    print("Alert: Helmets should be worn.")
!pip install twilio
from twilio.rest import Client

account_sid = 'AC25956216917b6e170390b4079adcefde'
auth_token = 'ce9a68d44d631430c1c8ed42b1f5c744'
client = Client(account_sid, auth_token)

message = client.messages.create(
  from_='+18284265141',
  to='+9',
  body="Alert: Only two people are allowed on a bike! have a safe ride and please wear the helmet." # Add the body parameter here
)

print(message.sid)

import cv2
import numpy as np
import tensorflow as tf

# Load pre-trained object detection model (e.g., YOLOv5)
model = tf.keras.models.load_model('/content/trained_model (1).h5')

def detect_phone_usage(detections, rider_bbox, phone_bbox):


    # Example: Check if phone is close to the rider's hand
    # Implement your own logic based on your data and analysis
    distance = np.linalg.norm(np.array(rider_bbox[:2]) - np.array(phone_bbox[:2]))
    if distance < 50: # Adjust threshold based on your data
        return True
    return False

# Load an image
# Make sure the path is correct and the image exists
image = cv2.imread('/content/tripleriding.jpeg')

# Check if the image loaded successfully
if image is None:
    print("Error: Could not load image. Please check the file path.")
else:
    # Preprocess the image to match the expected input shape
    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) # Convert to grayscale
    image = cv2.resize(image, (20, 20)) # Resize to 20x20
    image = np.expand_dims(image, axis=-1) # Add channel dimension
    image = np.expand_dims(image, axis=0) # Add batch dimension

    # Perform object detection
    detections = model.predict(image)

    # Print the shape and type of the detections object to help diagnose the issue
    print("Detections shape:", detections.shape)
    print("Detections type:", type(detections))

    # Print a sample of the detections to understand its structure
    print("Sample detections:", detections[0])

    # **You'll need to adapt the code below based on the actual structure of the `detections` object**
    # For example, if 'detections' is a NumPy array where the first 4 elements represent the bounding box:

    rider_bbox = None
    phone_bbox = None

    if detections.shape[1] >= 4: # Check if there are enough elements for a bounding box
        rider_bbox = detections[0, :6]  # Assuming the first detection is the rider


    # Analyze for phone usage
    if rider_bbox is not None and phone_bbox is not None:
        phone_usage_detected = detect_phone_usage(detections, rider_bbox, phone_bbox)
        if phone_usage_detected:
            print("Phone usage detected!")
        else:
            !pip install twilio
            from twilio.rest import Client

            account_sid = 'AC25956216917b6e170390b4079adcefde'
            auth_token = 'ce9a68d44d631430c1c8ed42b1f5c744'
            client = Client(account_sid, auth_token)

            message = client.messages.create(
            from_='+18284265141',
            to='+9',
            body="Alert: Please avoid using mobile phones while driving for everyone's safety. ." # Add the body parameter here
            )

            print(message.sid)

    cv2_imshow(image[0, :, :, 0])
    cv2.waitKey(0)
    cv2.destroyAllWindows()

!pip install ultralytics
!pip install twilio

import cv2
from ultralytics import YOLO
from google.colab.patches import cv2_imshow
from twilio.rest import Client

# Load the YOLOv5 model (replace with your model path if different)
model = YOLO('/content/yolov5s.pt')

# Load the image
img = cv2.imread('/content/helmet.jpg')

# Run YOLOv5 inference
results = model(img)

# Initialize flags for detection
helmet_detected = False
person_detected = False
no_helmet_detected = False

# Iterate over detection results
for box in results[0].boxes:
    # Extract class ID and bounding box coordinates
    class_id = box.cls.item()
    x1, y1, x2, y2 = map(int, box.xyxy.tolist()[0])

    if class_id == 0:  # Assuming 0 is the class ID for helmets
        helmet_detected = True
        cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)  # Green box for helmets
        cv2.putText(img, 'Helmet', (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)
    elif class_id == 1:  # Assuming 1 is the class ID for persons
        person_detected = True
        if not helmet_detected:
            no_helmet_detected = True
            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 0, 255), 2)  # Red box for persons without helmets
            cv2.putText(img, 'No Helmet', (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)
        else:
            cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 2)  # Blue box for persons with helmets
            cv2.putText(img, 'Person with Helmet', (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)

# Display the annotated image
cv2_imshow(img)

# Send alerts based on detections
if no_helmet_detected:
    # Twilio credentials
    account_sid = 'AC5a45088aad593c466d5801730df2168c'
    auth_token = 'd8a7694bf568a4eabfdae694cab858b6'

    client = Client(account_sid, auth_token)

    message = client.messages.create(
        from_='+13854817243',
        to='+num',
        body="Alert: Please wear a helmet!"
    )

    print(f"Twilio message sent: {message.sid}")
else:
    print("Good job! Everyone is wearing a helmet.")
cv2_imshow(image[0, :, :, 0])
cv2.waitKey(0)
cv2.destroyAllWindows()

!pip install ultralytics
!pip install twilio

import cv2
from ultralytics import YOLO
from google.colab.patches import cv2_imshow
from twilio.rest import Client

# Load the YOLOv5 model (replace with your model path if different)
model = YOLO('/content/yolov5s.pt')

# Load the image
img = cv2.imread('/content/riders-without-helmets.jpg')

# Run YOLOv5 inference
results = model(img)

# Initialize flags for detection
helmet_detected = False
person_detected = False
no_helmet_detected = False

# Iterate over detection results
for box in results[0].boxes:
    # Extract class ID and bounding box coordinates
    class_id = box.cls.item()
    x1, y1, x2, y2 = map(int, box.xyxy.tolist()[0])

    if class_id == 0:  # Assuming 0 is the class ID for helmets
        helmet_detected = True
        cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)  # Green box for helmets
        cv2.putText(img, 'Helmet', (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)
    elif class_id == 1:  # Assuming 1 is the class ID for persons
        person_detected = True
        if not helmet_detected:
            no_helmet_detected = True
            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 0, 255), 2)  # Red box for persons without helmets
            cv2.putText(img, 'No Helmet', (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)
        else:
            cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 2)  # Blue box for persons with helmets
            cv2.putText(img, 'Person with Helmet', (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)

# Display the annotated image
cv2_imshow(img)

# Send alerts based on detections
if no_helmet_detected:
    # Twilio credentials
    account_sid = 'AC5a45088aad593c466d5801730df2168c'
    auth_token = 'd8a7694bf568a4eabfdae694cab858b6'

    client = Client(account_sid, auth_token)

    message = client.messages.create(
        from_='+13854817243',
        to='+num',
        body="Alert: Please wear a helmet!"
    )
    print(message.sid)
else:
     print("Good job! Everyone is wearing a helmet.")
cv2_imshow(image[0, :, :, 0])
cv2.waitKey(0)
cv2.destroyAllWindows()